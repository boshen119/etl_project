{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "from splinter import Browser\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try scraping with BeautifulSoup only, not Splinter\n",
    "# executable_path = {'executable_path': '/Users/Bons/Downloads/chromedriver'}\n",
    "# browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of pages to be looped through\n",
    "url_list = []\n",
    "\n",
    "# URL of page to be scraped\n",
    "for i in range(1,50):\n",
    "    url = 'https://slickdeals.net/?page=' + str(i)\n",
    "    url_list.append(url)\n",
    "#     print(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sale_items = []\n",
    "\n",
    "# Trying to loop through pages 1-50 of Slickdeals.net\n",
    "for url in url_list:\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    soup = bs(response.text, 'html.parser')\n",
    "    \n",
    "    results = soup.find_all('div')\n",
    "    \n",
    "    #Create a dataframe to hold\n",
    "    \n",
    "    for result in results:\n",
    "    # Error handling\n",
    "        try:\n",
    "            # Identify and return title of listing\n",
    "            title = result.find('div', class_=\"priceLine\")\n",
    "            # Identify and return original price of listing\n",
    "            old_price = result.find('span', class_=\"oldListPrice\")\n",
    "#             old_price = old_price.text\n",
    "            # Identify and return new price of listing\n",
    "            new_price = result.find('div', class_=\"itemPrice\")\n",
    "#             new_price = new_price.text.strip()\n",
    "            # Print results only if title,a price, and link are available\n",
    "            if (title and old_price and new_price):\n",
    "                print('-------------')\n",
    "                print(\"Title\")\n",
    "                print(title[\"title\"])\n",
    "                print(\"Old Price\")\n",
    "                print(old_price.text)\n",
    "                print(\"New Price\")\n",
    "                print(new_price.text.strip())\n",
    "                sale_items.append({\"Item\" : title[\"title\"], \"Old Price\" : old_price.text, \"Sale Price\": new_price.text.strip()})\n",
    "        except AttributeError as e:\n",
    "            print(e)\n",
    "            \n",
    "#     browser.click_link_by_partial_text('Next')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sale_items_df = pd.DataFrame(sale_items)\n",
    "sale_items_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sale_items_df.append({\"Store\" : \"Slickdeals.net\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sale_items_df.to_csv(\"slickdeals.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_list_df = sale_items_df\n",
    "# master_list_df.columns\n",
    "# pick_up_method.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split item column after \"free\"\n",
    "\n",
    "# leaves \"free shipping\" and \"store pick up\"\n",
    "pick_up_method = pd.DataFrame(sale_items_df.Item.str.split('+').str[1])\n",
    "pick_up_method.to_csv('slickdeal_items_w_pickup.csv', index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drops the shipping/store pickup\n",
    "split_items = pd.DataFrame(sale_items_df.Item.str.split('+').str[0])\n",
    "split_items.to_csv(\"slickdeal_items.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_items_df = split_items.merge(pick_up_method, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_items_df = merged_items_df.rename(columns = {\"Item_x\" : \"Item\",\n",
    "                                  \"Item_y\" : \"Pick Up Notes\"})\n",
    "merged_items_df.to_csv('merged_item_columns.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up data and upload to a database"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
